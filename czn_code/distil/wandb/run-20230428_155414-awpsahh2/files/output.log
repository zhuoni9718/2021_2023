//users5/znchen/anaconda3/envs/q2k/lib/python3.10/site-packages/transformers-4.27.0.dev0-py3.10.egg/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Fine-tuning facebook/bart-large...
Using 2 GPUs
  0% 0/1549 [00:00<?, ?it/s]//users5/znchen/anaconda3/envs/q2k/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '


























































































 99% 1539/1549 [23:27<00:09,  1.10it/s]
Step: 100, Loss: 14.8809
Step: 200, Loss: 12.4983
Step: 300, Loss: 9.6644
Step: 400, Loss: 7.4167
Step: 500, Loss: 5.9850
Step: 600, Loss: 5.0212
Step: 700, Loss: 4.3300
Step: 800, Loss: 3.8109
Step: 900, Loss: 3.4058
Step: 1000, Loss: 3.0816
Step: 1100, Loss: 2.8152
Step: 1200, Loss: 2.5927
Step: 1300, Loss: 2.4042
Step: 1400, Loss: 2.2426
Step: 1500, Loss: 2.1022
100% 1549/1549 [23:36<00:00,  1.09it/s]






100% 233/233 [01:35<00:00,  2.44it/s]
Epoch 1/10, Validation Loss: 0.1131
saving to  ./tmp/generate_model/facebookbartlarge/R/facebookbartlarge_0





































































































100% 1549/1549 [26:11<00:00,  1.01s/it]
  0% 0/233 [00:00<?, ?it/s]
Step: 100, Loss: 0.1319
Step: 200, Loss: 0.1358
Step: 300, Loss: 0.1331
Step: 400, Loss: 0.1339
Step: 500, Loss: 0.1328
Step: 600, Loss: 0.1328
Step: 700, Loss: 0.1318
Step: 800, Loss: 0.1314
Step: 900, Loss: 0.1307
Step: 1000, Loss: 0.1300
Step: 1100, Loss: 0.1295
Step: 1200, Loss: 0.1287
Step: 1300, Loss: 0.1284
Step: 1400, Loss: 0.1278
Step: 1500, Loss: 0.1276




100% 233/233 [01:16<00:00,  3.05it/s]
Epoch 2/10, Validation Loss: 0.1037
saving to  ./tmp/generate_model/facebookbartlarge/R/facebookbartlarge_1






































































































 99% 1527/1549 [26:11<00:22,  1.02s/it]
Step: 100, Loss: 0.1215
Step: 200, Loss: 0.1200
Step: 300, Loss: 0.1194
Step: 400, Loss: 0.1185
Step: 500, Loss: 0.1177
Step: 600, Loss: 0.1172
Step: 700, Loss: 0.1167
Step: 800, Loss: 0.1163
Step: 900, Loss: 0.1161
Step: 1000, Loss: 0.1160
Step: 1100, Loss: 0.1158
Step: 1200, Loss: 0.1166
Step: 1300, Loss: 0.1445
Step: 1400, Loss: 0.1784
Step: 1500, Loss: 0.2031
100% 1549/1549 [26:17<00:00,  1.02s/it]





100% 233/233 [01:15<00:00,  3.09it/s]
Epoch 3/10, Validation Loss: 4.2900
saving to  ./tmp/generate_model/facebookbartlarge/R/facebookbartlarge_2






































































































 99% 1528/1549 [26:10<00:21,  1.01s/it]
Step: 100, Loss: 0.5232
Step: 200, Loss: 0.5157
Step: 300, Loss: 0.5163
Step: 400, Loss: 0.5104
Step: 500, Loss: 0.5092
Step: 600, Loss: 0.5076
Step: 700, Loss: 0.5087
Step: 800, Loss: 0.5038
Step: 900, Loss: 0.4993
Step: 1000, Loss: 0.4975
Step: 1100, Loss: 0.4958
Step: 1200, Loss: 0.4941
Step: 1300, Loss: 0.4943
Step: 1400, Loss: 0.4935
Step: 1500, Loss: 0.4931
100% 1549/1549 [26:13<00:00,  1.02s/it]




100% 233/233 [01:15<00:00,  3.09it/s]
Epoch 4/10, Validation Loss: 8.3933
saving to  ./tmp/generate_model/facebookbartlarge/R/facebookbartlarge_3






































































































 99% 1529/1549 [26:10<00:20,  1.02s/it]
Step: 100, Loss: 0.4662
Step: 200, Loss: 0.4726
Step: 300, Loss: 0.4745
Step: 400, Loss: 0.4774
Step: 500, Loss: 0.4765
Step: 600, Loss: 0.4744
Step: 700, Loss: 0.4751
Step: 800, Loss: 0.4749
Step: 900, Loss: 0.4739
Step: 1000, Loss: 0.4726
Step: 1100, Loss: 0.4720
Step: 1200, Loss: 0.4718
Step: 1300, Loss: 0.4718
Step: 1400, Loss: 0.4723
Step: 1500, Loss: 0.4719
100% 1549/1549 [26:13<00:00,  1.02s/it]




100% 233/233 [01:16<00:00,  3.03it/s]
Epoch 5/10, Validation Loss: 7.5191
saving to  ./tmp/generate_model/facebookbartlarge/R/facebookbartlarge_4






































































































 98% 1524/1549 [26:10<00:25,  1.04s/it]
Step: 100, Loss: 0.4723
Step: 200, Loss: 0.4717
Step: 300, Loss: 0.4666
Step: 400, Loss: 0.4658
Step: 500, Loss: 0.4659
Step: 600, Loss: 0.4655
Step: 700, Loss: 0.4659
Step: 800, Loss: 0.4646
Step: 900, Loss: 0.4643
Step: 1000, Loss: 0.4649
Step: 1100, Loss: 0.4661
Step: 1200, Loss: 0.4658
Step: 1300, Loss: 0.4661
Step: 1400, Loss: 0.4660
Step: 1500, Loss: 0.4653
100% 1549/1549 [26:17<00:00,  1.02s/it]





100% 233/233 [01:18<00:00,  2.97it/s]
  0% 0/1549 [00:00<?, ?it/s]
Epoch 6/10, Validation Loss: 10.7543






































































































 99% 1528/1549 [26:10<00:21,  1.02s/it]
Step: 100, Loss: 0.4623
Step: 200, Loss: 0.4577
Step: 300, Loss: 0.4590
Step: 400, Loss: 0.4565
Step: 500, Loss: 0.4595
Step: 600, Loss: 0.4601
Step: 700, Loss: 0.4601
Step: 800, Loss: 0.4615
Step: 900, Loss: 0.4624
Step: 1000, Loss: 0.4630
Step: 1100, Loss: 0.4639
Step: 1200, Loss: 0.4645
Step: 1300, Loss: 0.4632
Step: 1400, Loss: 0.4628
Step: 1500, Loss: 0.4620
100% 1549/1549 [26:14<00:00,  1.02s/it]




100% 233/233 [01:15<00:00,  3.08it/s]
Epoch 7/10, Validation Loss: 10.5241
saving to  ./tmp/generate_model/facebookbartlarge/R/facebookbartlarge_6






































































































100% 1549/1549 [26:15<00:00,  1.02s/it]
  0% 0/233 [00:00<?, ?it/s]
Step: 100, Loss: 0.4630
Step: 200, Loss: 0.4614
Step: 300, Loss: 0.4558
Step: 400, Loss: 0.4570
Step: 500, Loss: 0.4570
Step: 600, Loss: 0.4583
Step: 700, Loss: 0.4591
Step: 800, Loss: 0.4608
Step: 900, Loss: 0.4615
Step: 1000, Loss: 0.4617
Step: 1100, Loss: 0.4616
Step: 1200, Loss: 0.4606
Step: 1300, Loss: 0.4599
Step: 1400, Loss: 0.4598
Step: 1500, Loss: 0.4594




100% 233/233 [01:15<00:00,  3.09it/s]
Epoch 8/10, Validation Loss: 11.6998
saving to  ./tmp/generate_model/facebookbartlarge/R/facebookbartlarge_7



